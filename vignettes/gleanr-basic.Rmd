---
title: "Tutorial using GLEANR core functionality"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tutorial using GLEANR core functionality}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(gleanr)
library(data.table)
library(devtools)
```

Here we provide a single simple example of using `gleanr` on simulated data. While this doesn't comprehensively explore all of gleanr's options and functionality, we focus on the core components that will be helpful for most users.
As input, `gleanr` requires:
- A matrix (`B`) of GWAS effect size estimates (SNPs x traits), with the first column containing SNP identifiers and the first row containing trait labels
- A matrix (`S`) of GWAS standard error estimates (SNPs x traits, same order as B), with the first column containing SNP identifiers and the first row containing trait labels
- A matrix (`C`) of estimated correlation due to sample sharing between GWAS (necessary if you wish to adjust for the impact of sample sharing; traits x traits), with the first row containing trait labels and rows having a matching order (but no labels)
- A matrix (`C_se`) of standard error estimates corresponding to values in `C` (*optional* but recommended), in the same order as `C`.
- A list of variances across GWAS z-scores (*optional* to adjust correlation estimates for trait heritability), with traits ordered as in `B`

Note that `gleanr` can be run directly from the command line using input file paths (see the `gleanr_run.R` script in the [gleanr_workflow](https://github.com/aomdahl/gleanr_workflow/blob/main/src/gleaner_run.R) repository). 
*We recommend this for most use cases as the simplest way to run gleanr.* Please see this script for an example use case.

However, if users prefer to perform `gleanr` directly in R, users have a few options.
In the option we explore here, we use a wrapper `gleanr` function which takes as input data matrices and performs model selection and model fitting automatically.
In future tutorials, we will explore doing these manually to allow for greater user control.

## GLEANR analysis on simulated data
*The simulated data used here provides an example of what input to `gleanr` should look like. This was simulated as described in [here](https://github.com/aomdahl/gleanr_workflow/tree/main/manuscript_analyses/simulations) using Type 2 simulations, with N=200Km 1 large block of traits with sample sharing, V102 and U101*

To begin, load into memory all the necessary data, available with the `gleanr` package
```{r}
beta <- fread(system.file("extdata", "sim1.effect_sizes.txt", package = "gleanr"))
se <- fread(system.file("extdata", "sim1.std_error.txt", package = "gleanr"))
c.mat <- as.matrix(fread(system.file("extdata", "sim1.c_matrix.txt", package = "gleanr")))
c_se.mat <- as.matrix(fread(system.file("extdata", "sim1.c_se_matrix.txt", package = "gleanr")))
```
Get the trait and SNP names:
```{r}
trait_names <- names(beta)[-1]
snp_names <- unlist(beta$SNP)
```
Convert all data into matrices:
```{r}
beta_m <- as.matrix(beta[,-1])
W_s <- 1/as.matrix(se[,-1])
```

Now, we run gleanr, with arguments as follows:
- `beta_m`: the input matrix of effect size estimates
- `W_s`: the weights for adjustment of effect sizes, 1/SE
- `snp_names`: list of SNP names
- `trait_names`: trait names 
- `c.mat`: matrix of correlation due to sample sharing, unprocessed
- `c_se.mat`: corresponding matrices of standard errors for `c.mat` estimates.
- For clarity we explicitly call `K="GRID"`, which selects `K_init` using a grid search to minimize the BIC, and `conv_objective=0.005` to specify when our objective achieves convergence.
```{r}
res <- gleanr(beta_m,W_s, snp_names, trait_names, C=c.mat, covar_se=c_se.mat, K="GRID",conv_objective=0.005, verbosity=0)
```
That's the quickest way to run gleanr! 
## Visualizing `gleanr` outputs
For downstream analysis, many options exist including evaluating top factor SNPs, testing for enrichments with `LDSC`, and direct interpretation of factor weights.

Here, I just show a few visualization tools available in the sister repository, `gleanr_workflow`:
First, a heatmap of the output factors
```{r, fig.width=8, fig.height=4}
source("https://raw.githubusercontent.com/aomdahl/gleanr_workflow/refs/heads/main/src/plot_functions.R")
plotFactors(res$V,trait_names = trait_names,title = "gleanr tutorial heatmap")
```


Next, a barplot showing a similar thing
```{r,fig.width=8, fig.height=4}
plotFactorsBarplot(res$V,trait_names = trait_names, title="gleanr tutorial barplot ")
```


Finally, a plot showiing the percent variance explained of each factor:
```{r,fig.width=8, fig.height=4}
barplot(res$PVE,ylab=bquote(R^2), xlab="Factors")
```
